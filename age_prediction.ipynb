{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def transform_age_classes_one_hot(csv_path, output_csv):\n",
    "    \"\"\"\n",
    "    Transforms the age column into one-hot encoded classes and maps them as follows:\n",
    "    10-20 -> AGE_CLASS_0\n",
    "    20-30 -> AGE_CLASS_1\n",
    "    30-40 -> AGE_CLASS_2\n",
    "    40-50 -> AGE_CLASS_3\n",
    "    50+   -> AGE_CLASS_4\n",
    "\n",
    "    Parameters:\n",
    "    - csv_path (str): The path to the input CSV file.\n",
    "    - output_csv (str): The path to save the transformed CSV file.\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Define the bins and corresponding labels (age classes)\n",
    "    bins = [10, 20, 30, 40, 50, float('inf')]  # float('inf') is used to cover ages greater than 50\n",
    "    labels = [0, 1, 2, 3, 4]  # New labels for the classes\n",
    "\n",
    "    # Create a new column 'AGE_CLASS' based on the age bins\n",
    "    df['AGE_CLASS'] = pd.cut(df['AGE'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    # Drop rows where the AGE column is not in the defined range (i.e., NaN in AGE_CLASS)\n",
    "    df = df.dropna(subset=['AGE_CLASS'])\n",
    "\n",
    "    # Convert AGE_CLASS to integer type (as cut returns category type)\n",
    "    df['AGE_CLASS'] = df['AGE_CLASS'].astype(int)\n",
    "\n",
    "    # One-hot encode the AGE_CLASS column\n",
    "    one_hot_encoded_df = pd.get_dummies(df, columns=['AGE_CLASS'], prefix='AGE_CLASS')\n",
    "\n",
    "    # Save the one-hot encoded DataFrame to a new CSV file\n",
    "    one_hot_encoded_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Transformed data with one-hot encoded age classes saved to {output_csv}\")\n",
    "\n",
    "# Example usage:\n",
    "csv_path = 'demographics_csv/demo_keystroke.csv'  # Your input CSV path\n",
    "output_csv = 'demographics_csv/age_one_hot_all.csv'  # Output CSV path\n",
    "\n",
    "transform_age_classes_one_hot(csv_path, output_csv)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_path = 'demographics_csv/age_one_hot_all.csv'  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())\n"
   ],
   "id": "a199c984d01a627"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def balance_dataset(csv_path, output_csv):\n",
    "    \"\"\"\n",
    "    Balances the dataset so that each class has an equal number of samples by undersampling.\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_path (str): The path to the input CSV file with one-hot encoded age classes.\n",
    "    - output_csv (str): The path to save the balanced CSV file.\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Assuming that AGE_CLASS columns are one-hot encoded, first identify the classes\n",
    "    age_classes_columns = [col for col in df.columns if col.startswith('AGE_CLASS_')]\n",
    "    \n",
    "    # Create a new column 'AGE_CLASS' that contains the original class number (not one-hot encoded)\n",
    "    df['AGE_CLASS'] = df[age_classes_columns].idxmax(axis=1).apply(lambda x: int(x.split('_')[-1]))\n",
    "\n",
    "    # Find the minimum number of samples in any age class\n",
    "    min_samples = df['AGE_CLASS'].value_counts().min()\n",
    "\n",
    "    # Balance the dataset by undersampling each class to have `min_samples` number of rows\n",
    "    balanced_df = df.groupby('AGE_CLASS').apply(lambda x: x.sample(n=min_samples, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "    # Drop the temporary 'AGE_CLASS' column since you still have one-hot encoded columns\n",
    "    balanced_df = balanced_df.drop(columns=['AGE_CLASS'])\n",
    "\n",
    "    # Save the balanced DataFrame to a new CSV file\n",
    "    balanced_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Balanced dataset saved to {output_csv}\")\n",
    "\n",
    "# Step 1: Create the balanced dataset\n",
    "input_csv = 'demographics_csv/age_one_hot_all.csv'  # Input CSV path\n",
    "output_csv = 'demographics_csv/balanced_age.csv'  # Output CSV path\n",
    "\n",
    "balance_dataset(input_csv, output_csv)"
   ],
   "id": "f2de3cc279dabe9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# KNN\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('demographics_csv/balanced_age.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[col for col in df.columns if col.startswith('AGE_CLASS_')])\n",
    "y = df[[col for col in df.columns if col.startswith('AGE_CLASS_')]].idxmax(axis=1).apply(lambda x: int(x.split('_')[-1]))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform\n"
   ],
   "id": "4ba3a0d9a8865ae7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Classifier Accuracy: \", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ],
   "id": "babffccc8bb2470e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ANN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encode the target variable for ANN\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Build the ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(y_train_encoded.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_encoded)\n",
    "print(\"ANN Accuracy: \", test_acc)\n",
    "\n",
    "# Plotting training & validation accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='test accuracy')\n",
    "plt.title('ANN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "a3ec6a61c9ab8874"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
